{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-22T14:50:02.541512Z",
     "iopub.status.busy": "2023-06-22T14:50:02.540960Z",
     "iopub.status.idle": "2023-06-22T14:51:11.351602Z",
     "shell.execute_reply": "2023-06-22T14:51:11.350385Z",
     "shell.execute_reply.started": "2023-06-22T14:50:02.541478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install imagen-pytorch\n",
    "!pip install -U sentence-transformers\n",
    "!pip install einops-exts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T14:51:11.355661Z",
     "iopub.status.busy": "2023-06-22T14:51:11.355263Z",
     "iopub.status.idle": "2023-06-22T14:51:11.367014Z",
     "shell.execute_reply": "2023-06-22T14:51:11.365969Z",
     "shell.execute_reply.started": "2023-06-22T14:51:11.355629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "\n",
    "class AnimeFaceDataset(Dataset):\n",
    "    def __init__(self, path_to_dataset, path_to_faces_labels, transform):\n",
    "        self.imgs_path = path_to_dataset\n",
    "        # retrieve the list of images in the specified path. Path must end with /\n",
    "        self.images_names = glob.glob(self.imgs_path + \"*\") \n",
    "        # eventualmente quello di sotto puo' essere fatto senza pandas ? Vedere se conviene dataframe o dizionario\n",
    "        labels_df = pd.read_csv(path_to_faces_labels)\n",
    "        self.anime_faces_labels = labels_df.set_index('image')['prompt'].to_dict()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_names)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images_names[idx]\n",
    "        img_name = img_path.split(\"/\")[-1]\n",
    "        img_labels = self.anime_faces_labels[img_name]\n",
    "        # Carica l'immagine utilizzando PIL\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        # Converte l'immagine in un tensore\n",
    "        img_tensor = ToTensor()(image)\n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "            \n",
    "        return img_tensor, img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T14:51:11.369197Z",
     "iopub.status.busy": "2023-06-22T14:51:11.368838Z",
     "iopub.status.idle": "2023-06-22T14:51:11.392596Z",
     "shell.execute_reply": "2023-06-22T14:51:11.391370Z",
     "shell.execute_reply.started": "2023-06-22T14:51:11.369164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DA VEDERE\n",
    "def get_prompts_embeddings(prompts, encoder, tokenizer):\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        prompts,\n",
    "        return_tensors = \"pt\",\n",
    "        padding = 'longest',\n",
    "        max_length = 256,\n",
    "        truncation = True\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = encoder(input_ids=encoded.input_ids , attention_mask=encoded.attention_mask)\n",
    "        encoded_text = output.last_hidden_state.detach()\n",
    "\n",
    "    attn_mask = encoded.attention_mask.bool()\n",
    "    \n",
    "    return encoded_text.masked_fill(~rearrange(attn_mask, '... -> ... 1'), 0.)\n",
    "\n",
    "def train(dataloader, imagen, encoder, tokenizer, trainer, unet_to_train, imagen_test): \n",
    "    i = 0\n",
    "    \n",
    "    for idx,batch in enumerate(dataloader):\n",
    "        images, prompts = batch[0], batch[1]\n",
    "        prompts = list(prompts)\n",
    "        # prendere le immagini \n",
    "        images = images.cuda()\n",
    "        # trasformare labels in text embeddings\n",
    "    \n",
    "        prompts_embeddings = get_prompts_embeddings(prompts, encoder, tokenizer).cuda()\n",
    "                \n",
    "        loss_unet = trainer(\n",
    "            images,\n",
    "            text_embeds = prompts_embeddings,\n",
    "            unet_number = unet_to_train,            # training on unet number 1 in this example, but you will have to also save checkpoints and then reload and continue training on unet number 2\n",
    "            max_batch_size = 8        # auto divide the batch of 64 up into batch size of 4 and accumulate gradients, so it all fits in memory\n",
    "        )\n",
    "        \n",
    "        trainer.update(unet_number = unet_to_train)\n",
    "            \n",
    "        print(i)\n",
    "    \n",
    "        i += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T14:51:11.395907Z",
     "iopub.status.busy": "2023-06-22T14:51:11.395430Z",
     "iopub.status.idle": "2023-06-22T14:51:41.800842Z",
     "shell.execute_reply": "2023-06-22T14:51:41.799662Z",
     "shell.execute_reply.started": "2023-06-22T14:51:11.395873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "\n",
    "from imagen_pytorch import Unet, SRUnet256, Imagen, ImagenTrainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# unet for imagen\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = 256,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True, True),\n",
    "    layer_cross_attns = (False, True, True, True)\n",
    ")\n",
    "\n",
    "\n",
    "# imagen, which contains the unets above (base unet and super resoluting ones)\n",
    "\n",
    "imagen = Imagen(\n",
    "    unets = unet1,\n",
    "    text_encoder_name = 't5-large',\n",
    "    image_sizes = 64,\n",
    "    timesteps = 1000,\n",
    "    cond_drop_prob = 0.1\n",
    ").cuda()\n",
    "\n",
    "trainer = ImagenTrainer(imagen).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T14:51:41.803578Z",
     "iopub.status.busy": "2023-06-22T14:51:41.802248Z",
     "iopub.status.idle": "2023-06-22T14:53:43.588676Z",
     "shell.execute_reply": "2023-06-22T14:53:43.587601Z",
     "shell.execute_reply.started": "2023-06-22T14:51:41.803541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = 'google/t5-v1_1-large'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, model_max_length=256)\n",
    "encoder = T5EncoderModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T15:41:53.343285Z",
     "iopub.status.busy": "2023-06-22T15:41:53.342298Z",
     "iopub.status.idle": "2023-06-22T15:41:53.706424Z",
     "shell.execute_reply": "2023-06-22T15:41:53.705400Z",
     "shell.execute_reply.started": "2023-06-22T15:41:53.343248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "size_of_batch = 8\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((64,64)),\n",
    "    ])\n",
    "\n",
    "anime_face_dataset = AnimeFaceDataset(\"../input/another-anime-face-dataset/animefaces256cleaner/\", \"../input/anime-faces-labels-cleaned/anime_faces_labels_cleaned.csv\", train_transform)\n",
    "dataloader = DataLoader(anime_face_dataset, batch_size=size_of_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-22T15:41:55.061563Z",
     "iopub.status.busy": "2023-06-22T15:41:55.061176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train(dataloader, imagen, encoder, tokenizer, trainer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T15:41:07.939357Z",
     "iopub.status.idle": "2023-06-22T15:41:07.941763Z",
     "shell.execute_reply": "2023-06-22T15:41:07.941494Z",
     "shell.execute_reply.started": "2023-06-22T15:41:07.941468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images = imagen.sample(\n",
    "    texts = [\n",
    "        'anime girl with long red hair, blue eyes, smug face',\n",
    "        'anime girl with short blue hair, red eyes'\n",
    "    ],\n",
    "    start_at_unet_number = 1,              \n",
    "    cond_scale = 2.).cuda()\n",
    "\n",
    "# Assuming you have a PyTorch tensor named 'tensor_img' with shape [1, 3, 256, 256]\n",
    "# Convert tensor to a NumPy array\n",
    "numpy_img = images[1].squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.imshow(numpy_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 923624,
     "sourceId": 2154267,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3497480,
     "sourceId": 6105348,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30497,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
